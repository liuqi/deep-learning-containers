FROM ubuntu:20.04

LABEL maintainer="VMware AI"
LABEL dlc_major_version="1"

ARG PYTHON=python3.9
ARG PYTHON_PIP=python3-pip
ARG PIP=pip3
ARG PYTHON_VERSION=3.9.10

# ENV variable to be passed to SageMaker stage
ENV PIP=${PIP}
ENV PYTHON=${PYTHON}

# See http://bugs.python.org/issue19846
ENV LANG=C.UTF-8
# Python wonâ€™t try to write .pyc or .pyo files on the import of source modules
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV LD_LIBRARY_PATH='/usr/local/lib:$LD_LIBRARY_PATH'
ENV MODEL_BASE_PATH=/models
# The only required piece is the model name in order to differentiate endpoints
ENV MODEL_NAME=model
ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update \
 && apt-get -y install --no-install-recommends \
    curl \
    gnupg2 \
    ca-certificates \
    emacs \
    git \
    unzip \
    wget \
    vim \
    libbz2-dev \
    liblzma-dev \
    libffi-dev \
    build-essential \
    zlib1g-dev \
    openssl \
    libssl1.1 \
    libreadline-gplv2-dev \
    libncursesw5-dev \
    libssl-dev \
    libsqlite3-dev \
    tk-dev \
    libgdbm-dev \
    libc6-dev \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

# Install python3.8
RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz \
 && tar -xvf Python-$PYTHON_VERSION.tgz \
 && cd Python-$PYTHON_VERSION \
 && ./configure && make && make install \
 && rm -rf ../Python-$PYTHON_VERSION* \
 # Starting from Python39, a xxx.pem file will be generated under /tmp folder during installation. Remove it to complete cleanup after installation from python source.
 && rm /tmp/*.pem

RUN ${PIP} --no-cache-dir install --upgrade \
    pip \
    setuptools

RUN ${PIP} install --no-cache-dir \
    boto3 \
    cython==0.29.21 \
    gevent==21.1.1 \
    requests==2.25.1 \
    grpcio==1.34.1 \
    protobuf==3.14.0 \
# using --no-dependencies to avoid installing tensorflow binary
 && ${PIP} install --no-dependencies --no-cache-dir \
    tensorflow-serving-api=="2.8.0"

# Some TF tools expect a "python" binary
RUN ln -s $(which ${PYTHON}) /usr/local/bin/python \
 && ln -s $(which ${PIP}) /usr/bin/pip

# RUN curl $TFS_URL -o /usr/bin/tensorflow_model_server \
#  && chmod 555 /usr/bin/tensorflow_model_server

# Install tensorflow_model_server
RUN echo 'deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal' >> /etc/apt/sources.list \
 && curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add - \
 && apt-get update \
 && apt-get -y install tensorflow-model-server \
#  && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

# Expose ports
# gRPC and REST
EXPOSE 8500 8501

# Set where models should be stored in the container
RUN mkdir -p ${MODEL_BASE_PATH}

# Create a script that runs the model server so we can use environment variables
# while also passing in arguments from the docker command line
RUN echo '#!/bin/bash \n\n' > /usr/bin/tf_serving_entrypoint.sh \
 && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} "$@"' >> /usr/bin/tf_serving_entrypoint.sh \
 && chmod +x /usr/bin/tf_serving_entrypoint.sh

CMD ["/usr/bin/tf_serving_entrypoint.sh"]